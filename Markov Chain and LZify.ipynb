{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Student Name:\n",
    "#### Student ID:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain, LZify\n",
    "\n",
    "Instructions: \n",
    "\n",
    "* This notebook is an interactive assignment; please read and follow the instructions in each cell. \n",
    "\n",
    "* Cells that require your input (in the form of code or written response) will have 'Question #' above.\n",
    "\n",
    "* After completing the assignment, please submit this notebook as a PDF.\n",
    "\n",
    "* Make sure to mark the page with your solution for each problem on Gradescope. Any problems without the correct pages marked may receive a score of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov-Based Chord Prediction\n",
    "\n",
    "In music, certain chord transitions are more likely than others. This idea can be applied as Markov Models, where the first-order temporal relationships between the various chords are captured by the transition probability matrix $A$. \n",
    "\n",
    "If we consider only major and minor chords, there are a total of 24 chords in this model (12 major, from C through B, and 12 minor, from C through B), formalized as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\label{eq:ChordReco:HMM:App:Spec:SetStates}\n",
    "  \\mathcal{A} = \\{\\mathbf{C},\\mathbf{C}^\\sharp,\\ldots,\\mathbf{B},\\mathbf{Cm},\\mathbf{Cm^\\sharp},\\ldots,\\mathbf{Bm}\\} \n",
    "\\end{equation}\n",
    "\n",
    "We use the notation $\\alpha{i}\\rightarrow\\alpha{j}$ referring to the transition from state $\\alpha{i}$ to state $\\alpha{j}$, $i,j\\in[1:24]$. For example, the coefficient $a_{1,2}$ expresses the \n",
    "probability for the transition $\\alpha_{1}\\rightarrow\\alpha_{2}$ (corresponding to  $\\mathbf{C}\\rightarrow\\mathbf{C}^\\sharp$), whereas $a_{1,8}$ expresses the probability for $\\alpha_{1}\\rightarrow\\alpha_{8}$  (corresponding to  $\\mathbf{C}\\rightarrow\\mathbf{G}$). In real music, the change from a tonic to the dominant is much more likely\n",
    "than transposing by one semitone, so that the probability $a_{1,8}$ should be much larger than $a_{1,2}$. The coefficients $a_{i,i}$ express the probability of staying in state $\\alpha_{i}$ (i.e., $\\alpha_{i}\\rightarrow\\alpha_{i}$), $i\\in[1:24]$. These coefficients are also referred to as **self-transition** probabilities.\n",
    "\n",
    "A transition probability matrix can be specified in many ways. For example, the matrix may be defined manually by a music expert based on rules from harmony theory. The most common approach is to generate such a matrix automatically \n",
    "by estimating the transition probabilities from labeled data. \n",
    "\n",
    "In the following exercise, you will create a Markov model by determining transition probabilities found in the music of the Beatles using bigrams (pairs of adjacent elements) in labeled frame sequences from a subset of the Beatles Corpus.\n",
    "\n",
    "For this assignment, assume each row in the dataset represents a chord that has followed the chord on the previous row in a Beatles song. When parsing the file for your model, you may discard any chord references beyond key and major/minor quality. For example, if a row reads 'Bbm7', you would parse for the key (B-flat) and quality (minor), but discard the extra information that it is a 7th chord.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mido\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy.random import multinomial as randm\n",
    "from numpy import where\n",
    "import scipy.signal as si\n",
    "import IPython.display as ipd\n",
    "from matplotlib import patches\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import scipy\n",
    "import librosa.display as ld\n",
    "import music21\n",
    "from music21 import midi as midi21\n",
    "from music21 import stream\n",
    "#from jchord.progressions import ChordProgression, MidiConversionSettings\n",
    "import copy\n",
    "import time\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.read_csv('Liverpool_band_chord_sequence.csv')\n",
    "\n",
    "def preprocess(df):\n",
    "    df[df['chords'] == 'Bb'] = 'A#'  \n",
    "    chords = ' '.join(map(str, df['chords']))\n",
    "    return chords\n",
    "\n",
    "data = preprocess(data)\n",
    "\n",
    "\n",
    "def play(x):\n",
    "\n",
    "    # Define the mapping between chord names and frequencies\n",
    "    chord_mapping = {\n",
    "    'C': [261.63, 329.63, 392.00],\n",
    "    'C#': [277.18, 349.23, 415.30],\n",
    "    'Db': [277.18, 349.23, 415.30],\n",
    "    'D': [293.66, 369.99, 440.00],\n",
    "    'D#': [311.13, 392.00, 466.16],\n",
    "    'Eb': [311.13, 392.00, 466.16],\n",
    "    'E': [329.63, 415.30, 493.88],\n",
    "    'F': [349.23, 440.00, 523.25],\n",
    "    'F#': [369.99, 466.16, 554.37],\n",
    "    'Gb': [369.99, 466.16, 554.37],\n",
    "    'G': [392.00, 493.88, 587.33],\n",
    "    'G#': [415.30, 523.25, 622.25],\n",
    "    'Ab': [415.30, 523.25, 622.25],\n",
    "    'A': [440.00, 554.37, 659.26],\n",
    "    'A#': [466.16, 587.33, 698.46],\n",
    "    'Bb': [466.16, 587.33, 698.46],\n",
    "    'B': [493.88, 622.25, 739.99]\n",
    "    'Cm': [261.63, 311.13, 392.00],\n",
    "    'Dbm': [277.18, 329.63, 415.30],\n",
    "    'Dm': [293.66, 349.23, 440.00],\n",
    "    'Ebm': [311.13, 369.99, 466.16],\n",
    "    'Em': [329.63, 392.00, 493.88],\n",
    "    'Fm': [349.23, 415.30, 523.25],\n",
    "    'Gbm': [369.99, 440.00, 554.37],\n",
    "    'Gm': [392.00, 466.16, 587.33],\n",
    "    'Abm': [415.30, 493.88, 622.25],\n",
    "    'Am': [440.00, 523.25, 659.26],\n",
    "    'Bbm': [466.16, 554.37, 698.46],\n",
    "    'Bm': [493.88, 587.33, 739.99]\n",
    "    }\n",
    "\n",
    "    # Define the chord progression\n",
    "    chord_progression = x.split()\n",
    "\n",
    "    # Define the duration of each chord (in seconds)\n",
    "    chord_duration = 1.5\n",
    "\n",
    "    # Set the sample rate (number of samples per second)\n",
    "    sample_rate = 44100\n",
    "\n",
    "    # Create an empty list to store the audio samples\n",
    "    audio_samples = []\n",
    "\n",
    "    # Generate the audio samples for each chord\n",
    "    for chord_name in chord_progression:\n",
    "        # Get the frequencies for the chord\n",
    "        chord_freqs = chord_mapping[chord_name]\n",
    "\n",
    "        # Generate sine waves for each note in the chord\n",
    "        chord_wave = np.zeros(int(chord_duration * sample_rate))\n",
    "        t = np.linspace(0, chord_duration, int(chord_duration * sample_rate), endpoint=False)\n",
    "        for freq in chord_freqs:\n",
    "            chord_wave += np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "        # Normalize the chord wave\n",
    "        chord_wave /= np.max(chord_wave)\n",
    "\n",
    "        # Append the chord wave to the audio samples list\n",
    "        audio_samples.extend(chord_wave)\n",
    "\n",
    "    # Convert the audio samples to a NumPy array\n",
    "    audio_samples = np.array(audio_samples)\n",
    "\n",
    "    # Play the chord progression in the Jupyter Notebook\n",
    "    audio_jupyter = Audio(audio_samples, rate=sample_rate)\n",
    "\n",
    "    display(audio_jupyter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 1 (20 points)\n",
    "\n",
    "Using the above data, generate a 24x24 matrix, where each matrix element (i,j) is the transition probability from chord i to chord j. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MM = np.zeros((24,24))\n",
    "\n",
    "### Your code here: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transition_matrix(A, ax=None, xlabel='State $a_j$', ylabel='State $a_i$', title='', clim=[-6, 0], cmap='gray_r'):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot the transition matrix with a colorbar\n",
    "    im = ax.imshow(A, origin = 'lower', aspect = 'auto',cmap='Blues')\n",
    "\n",
    "    # Set the tick labels\n",
    "    ax.set_xticks(np.arange(len(A)))\n",
    "    ax.set_yticks(np.arange(len(A)))\n",
    "    ax.set_xticklabels(np.arange(1, len(A) + 1))\n",
    "    ax.set_yticklabels(np.arange(1, len(A) + 1))\n",
    "\n",
    "    # Set the axis labels\n",
    "    ax.set_xlabel('From')\n",
    "    ax.set_ylabel('To')\n",
    "\n",
    "    # Create a colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "    # Set the colorbar label\n",
    "    cbar.ax.set_ylabel('Weight', rotation=-90, va=\"bottom\")\n",
    "\n",
    "    chroma_label = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']\n",
    "    chord_label_maj = chroma_label\n",
    "    chord_label_min = [s + 'm' for s in chroma_label]\n",
    "    chord_labels = chord_label_maj + chord_label_min\n",
    "    chord_labels_squeezed = chord_labels.copy()\n",
    "    for k in [13, 15, 17, 18, 20, 22]:\n",
    "        chord_labels_squeezed[k] = ''\n",
    "        \n",
    "    plt.xticks(np.arange(24), labels=chord_labels_squeezed )\n",
    "    plt.yticks(np.arange(24), labels=chord_labels)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()    \n",
    "\n",
    "plot_transition_matrix(MM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 (10 points)\n",
    "\n",
    "Using your MM, you will create your own 16-measure Beatles hits!\n",
    "For your first song, beginning on C major, select each next chord by choosing the chord with the largest transition probability from the current chord.\n",
    "\n",
    "Make sure your chord progression string is formatted like this: 'C Dm G C'\n",
    "\n",
    "Otherwise, it may not play in the in-browser MIDI player. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_first_beatles_hit = ''\n",
    "\n",
    "### Your code here:\n",
    "\n",
    "\n",
    "print(my_first_beatles_hit)\n",
    "play(my_first_beatles_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 3 (10 points)\n",
    "\n",
    "For your second song, beginning on C major, select each next chord at random according to the probabilities of your MM.\n",
    "For example, if C major transitions to G major with probability .5, F major with probability .25, and D minor with probability .25, then your next chord should be selected randomly from (G, F, Dm) with probability of selection (.5, .25, .25) respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_second_beatles_hit = ''\n",
    "\n",
    "### Your code here:\n",
    "\n",
    "\n",
    "print(my_second_beatles_hit)\n",
    "play(my_second_beatles_hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LZify: Applying Universal Prediction to Musical Style\n",
    "\n",
    "LZify was the first algorithmic learning method to create a style immitation from a dictionary of motifs of variable size. It is based on the Lempel-Ziv compression method. Because the viriable context (motif) size that is used for perdiction of the next note, the method became also know as Variable Memory Markov model. Strictly speaking, is not a correct term, but LZ prediciton is known to perform asymptotically as good as any finite Markov model, so the terminology is partially justified. \n",
    "\n",
    "In this section, you will implement the Incremental Parsing (IP) from the Lempel Ziv LZ78 method for creating a dictionary of motifs. These motifs are later used to generate new sequences resembling the input sequence.\n",
    "\n",
    "Please read the algorithm in Assayag, Dubnov, and Delerue's \"Guessing the Composerâ€™s Mind\" (available at https://pdfs.semanticscholar.org/0181/236e1b417c8dd5dddd1f919583893f7a9026.pdf). \n",
    "\n",
    "The IPMotif function should compute the motif dictionary discovered in the text. It uses Incremental Parsing method to parse the text into unseen motifs.\n",
    "\n",
    "##### Question 4 (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPMotif(text):\n",
    "    \"\"\"Compute an associative dictionary (the motif dictionary).\"\"\"\n",
    "    \n",
    "    dictionary = {}\n",
    "    \n",
    "    ### Your Code Here:\n",
    "\n",
    "    \n",
    "    \n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text below contains an excerpt of Beethoven's Fur Elise, written as MML (Music Macro Language). MML is used to represent musical melodies as text. \n",
    "\n",
    "You can read more about MML syntax here: https://en.wikipedia.org/wiki/Music_Macro_Language\n",
    "\n",
    "You can play with MML in this webapp: https://msxplay.com/editor.html\n",
    "\n",
    "Try playing the text from the cell below in the webapp to hear sample output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ";[name=scc lpf=1]\n",
    "\n",
    "#opll_mode 1\n",
    "\n",
    "#tempo 150\n",
    "\n",
    "#title { \"Output\"}\n",
    "\n",
    "@s00 = { 2B343E3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F3F403E2DC0CD273A }\n",
    "\n",
    "@s01 = { C3CFD3D0D1DAE6F2000A27383D3E3C3E403F3B352A0EF8EEEFF4E9DDD4CCC6C0 }\n",
    "\n",
    "@s02 = { 3E383230302F2B200DF6E0D0C7C5C4C4C3C1C0C6D5E9FB050B0C0D111B2A3840 }\n",
    "\n",
    "@s03 = { CCC7C3C0C1C4CDDAED021A2D3A403E3A332C251D160F0903FDF7F0EAE4DED7D1 }\n",
    "\n",
    "@s04 = { 3D403D36302D303A3F24E0C2DDE6D7CBC3C0C3CAD0D3D0C6C1DC203E231A2935 }\n",
    "\n",
    "@s05 = { 05FFF2DFCCC0CE003932DCD127401AF9E8E0DDDCDEE2E5ECF2F900030A0C0E0C }\n",
    "\n",
    "@s06 = { F5F5F1ECE5DDD4CAC0C1D708403A0E050C0703020301000000FFFFFFFDFDFBF8 }\n",
    "\n",
    "@s07 = { 003F3F3F3F3F3F3F402BF6D2C6C4C6CACCC7C0C8EA1E3E3F3F3F3F3F3F3F3F3F }\n",
    "\n",
    "@s08 = { 00242423211C18110B0600FBF6F3F0F0F2F7FF0A1A304758552FEAB0ADD6FF16 }\n",
    "\n",
    "@s09 = { B2252524221D19110C0600FAF6F2F0F0F2F7FF0A1B31495A5730E9ADAAD5FF16 }\n",
    "\n",
    "@s10 = { D13232312F272118100801F8F2EDEAEAECF4FE0E2543637B7642E1908BC5FF1E }\n",
    "\n",
    "@s11 = { BD252625231D19120C0600FAF6F2F0EFF1F7FF0A1C324A5C5931E9ACA9D4FF17 }\n",
    "\n",
    "@s12 = { E45B5C5955483D2C1D1002F2E6DDD7D7DCE9FC19447BB5E0D878C8332B94FD37 }\n",
    "\n",
    "@s13 = { FF131313120F0D09060300FDFBF9F8F8F9FC00050E1A262F2D19F4D5D3EA000B }\n",
    "\n",
    "@s14 = { 191919181713100C080400FCF9F7F5F5F7FAFF061221313D3A20F1C9C6E3000F }\n",
    "\n",
    ";      Mode,nFreq, AL, AR, DR, SL, SR, RR\n",
    "@r0 = {   0,    0,128, 32, 12,128,  2,  4}\n",
    "@r1 = {   0,    0,255,255, 12,128,  2,  4}\n",
    "\n",
    "; C G F Em /C\n",
    "\n",
    "4567 v12@0@r1 l4o4q5\n",
    "\n",
    "4   [PASTE YOUR MML TEXT HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another option to listen to your generated MML text played with a piano instead of the synthetic sound on MSXplay, go to https://archeagemmllibrary.com/a-ha-take-on-me/\n",
    "\n",
    "In your browser, find the option to Inspect Element, and edit the MML text to instead contain your composition.\n",
    "\n",
    "Be sure to add a prefix of t180 to your MML output in order to set the tempo. \n",
    "(Special thanks to Alex Simonyan for this in-browser MML hack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'o6ed+ed+ec-dc>aceabeg+bb+e<ed+ed+ec-dc>aceabe<c>bab<cde>g<fed>f<edc>e<dc>be<eeed+ed+ec-dc>aceabeg+bb+e<ed+ed+ec-dc>aceabe<c>ba'\n",
    "dict1 = IPMotif(text)\n",
    "print(dict1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, implement the IPContinuation and Normalize functions. \n",
    "The IPContinuation function transforms the IPMotif dictionary into a tree-like representation to allow finding continuations for new  motifs. The Normalize function turns the counters in every element of the IPContinuation dictionary into probabilities. \n",
    "\n",
    "##### Question 5 (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPContinuation(dict1):\n",
    "    \"\"\"Compute continuation dictionary from a motif dictionary\"\"\"\n",
    "    \n",
    "    dict2 = {}\n",
    "\n",
    "    ### Your Code Here: \n",
    "    \n",
    "    \n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 6 (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize(dict2):\n",
    "    \"\"\"Turns the counters in every element of dict2 to probabilities\"\"\"\n",
    "\n",
    "    ### Your Code Here:\n",
    "    \n",
    "\n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2 = IPContinuation(dict1)\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generting a new sequence is done by traversing the IPContinuation tree and selecting possible branches according to their weights. If motif is not found, its last symbol is removed and the process is repeated for a shorter motif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPGenerate(n,dict2):\n",
    "    p = 0\n",
    "    out = \"\"\n",
    "    for k in range(n):\n",
    "        while True:\n",
    "            context = out[-p:]\n",
    "            if context in dict2:\n",
    "                prob = [tup[1] for tup in dict2[context]]\n",
    "                conti = where(randm(1,prob))[0][0]\n",
    "                cont = dict2[context][conti][0]\n",
    "                out = out + cont\n",
    "                break\n",
    "            else:\n",
    "                p = p-1\n",
    "    return out\n",
    "out = IPGenerate(92,dict2)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 7 (10 points)\n",
    "\n",
    "Paste your output in the online MML player, and listen to your piece. Do you hear elements of Fur Elise in your composition? What are some of the differences in the output from the original? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Your response here ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few important points:\n",
    "1. The method captures the \"texture\" of the language but not it's meaning.\n",
    "2. We could parse a new text using IPMotifs from two languages, then count the length and number of motifs in order to decide what was the language of the new text.\n",
    "3. In order to use this method with musical information, we need first to translate audio to features, or in case of polyphonic midi change this into some proper representation. One possibility is using virtual fundamental or chroma for harmony, or some other specialized representation to capture repetition in terms of other specific musical properties."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
